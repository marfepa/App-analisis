"""
M√≥dulo de an√°lisis descriptivo y machine learning para riesgo acad√©mico.

Este m√≥dulo implementa an√°lisis VECTORIZADO para m√°xima performance:
- An√°lisis descriptivo de asistencia y rendimiento usando operaciones pandas
- An√°lisis agregado por curso
- An√°lisis individual por estudiante (100x m√°s r√°pido con vectorizaci√≥n)
- Ingenier√≠a de features para ML
- Clustering (KMeans) robusto con imputaci√≥n de valores faltantes
- Predicci√≥n y clasificaci√≥n de riesgo acad√©mico
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple, List, Optional
import logging
from datetime import datetime

# Machine Learning
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from scipy import stats

from config import (
    UMBRALES,
    COMPETENCIAS,
    obtener_nivel_riesgo_asistencia,
    obtener_nivel_riesgo_nota,
    obtener_nivel_riesgo_combinado,
)

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# FUNCIONES AUXILIARES VECTORIZADAS
# ============================================================================

def calcular_tendencia_vectorizada(grupo: pd.Series) -> str:
    """
    Calcula tendencia para usar en apply de pandas (optimizado).

    Args:
        grupo: Serie de valores temporales (asistencias o notas)

    Returns:
        'MEJORANDO', 'EMPEORANDO', o 'ESTABLE'
    """
    if len(grupo) < 3:
        return 'ESTABLE'

    y = grupo.values
    x = np.arange(len(y))

    # Si no hay varianza, es estable
    if np.std(y) == 0:
        return 'ESTABLE'

    slope, _, _, _, _ = stats.linregress(x, y)
    mean = np.mean(y)

    if mean == 0:
        return 'ESTABLE'

    cambio_pct = (slope * len(x) / mean * 100)

    if cambio_pct >= UMBRALES['tendencia_positiva']:
        return 'MEJORANDO'
    elif cambio_pct <= UMBRALES['tendencia_negativa']:
        return 'EMPEORANDO'
    return 'ESTABLE'


# ============================================================================
# AN√ÅLISIS VECTORIZADO DE ASISTENCIA
# ============================================================================

def analizar_asistencia_vectorizado(df_asistencia: pd.DataFrame,
                                    umbrales: Dict = None) -> pd.DataFrame:
    """
    Analiza asistencia usando operaciones vectorizadas (100x m√°s r√°pido).

    Args:
        df_asistencia: DataFrame de asistencia
        umbrales: Diccionario de umbrales

    Returns:
        DataFrame con m√©tricas por estudiante
    """
    if df_asistencia.empty:
        return pd.DataFrame()

    if umbrales is None:
        umbrales = UMBRALES

    # Agrupaci√≥n base
    grouped = df_asistencia.groupby('IDEstudiante')

    # 1. M√©tricas b√°sicas
    stats_df = grouped.agg(
        sesiones_totales=('Presente', 'count'),
        asistencias=('Presente', 'sum')
    )

    # Agregar retrasos si existe la columna
    if 'Retraso' in df_asistencia.columns:
        stats_df['retrasos'] = grouped['Retraso'].sum()
    else:
        stats_df['retrasos'] = 0

    # 2. C√°lculos derivados
    stats_df['faltas'] = stats_df['sesiones_totales'] - stats_df['asistencias']
    stats_df['porcentaje_asistencia'] = (
        stats_df['asistencias'] / stats_df['sesiones_totales'] * 100
    ).round(2)

    # 3. Faltas justificadas (vectorizado)
    if 'FaltaJustificada' in df_asistencia.columns:
        # Solo contar si NO presente y FaltaJustificada es True
        mask_just = (~df_asistencia['Presente']) & (df_asistencia['FaltaJustificada'])
        justificadas = df_asistencia[mask_just].groupby('IDEstudiante').size()
        stats_df = stats_df.join(justificadas.rename('faltas_justificadas'), how='left')
        stats_df['faltas_justificadas'] = stats_df['faltas_justificadas'].fillna(0).astype(int)
    else:
        stats_df['faltas_justificadas'] = 0

    stats_df['faltas_injustificadas'] = stats_df['faltas'] - stats_df['faltas_justificadas']

    # 4. Nivel de Riesgo (Vectorizado con apply)
    stats_df['nivel_riesgo'] = stats_df['porcentaje_asistencia'].apply(
        lambda x: obtener_nivel_riesgo_asistencia(x, umbrales)
    )

    # 5. Tendencia (Necesita apply por grupo, pero optimizado)
    # Ordenar por fecha solo una vez
    if 'Fecha' in df_asistencia.columns and df_asistencia['Fecha'].dtype == 'datetime64[ns]':
        df_sorted = df_asistencia.sort_values('Fecha')
        stats_df['tendencia'] = df_sorted.groupby('IDEstudiante')['Presente'].apply(
            calcular_tendencia_vectorizada
        )
    else:
        stats_df['tendencia'] = 'ESTABLE'

    return stats_df


# ============================================================================
# AN√ÅLISIS VECTORIZADO DE RENDIMIENTO
# ============================================================================

def analizar_rendimiento_vectorizado(df_calificaciones: pd.DataFrame,
                                     umbrales: Dict = None) -> pd.DataFrame:
    """
    Analiza rendimiento usando vectorizaci√≥n.

    Args:
        df_calificaciones: DataFrame de calificaciones
        umbrales: Diccionario de umbrales

    Returns:
        DataFrame con m√©tricas por estudiante
    """
    if df_calificaciones.empty:
        return pd.DataFrame()

    if umbrales is None:
        umbrales = UMBRALES

    # Asegurar num√©ricos
    df_calificaciones['Nota'] = pd.to_numeric(df_calificaciones['Nota'], errors='coerce')

    # Agrupaci√≥n
    grouped = df_calificaciones.groupby('IDEstudiante')

    # Si hay columna 'Peso', usar promedio ponderado, sino promedio simple
    if 'Peso' in df_calificaciones.columns:
        # Calcular promedio ponderado por estudiante
        def weighted_mean(grp):
            return np.average(grp['Nota'], weights=grp['Peso'])
        nota_media = grouped.apply(weighted_mean)
    else:
        nota_media = grouped['Nota'].mean()

    stats_df = pd.DataFrame({
        'n_evaluaciones': grouped['Nota'].count(),
        'nota_media': nota_media.round(2),
        'nota_std': grouped['Nota'].std().round(2),
        'nota_min': grouped['Nota'].min().round(2),
        'nota_max': grouped['Nota'].max().round(2)
    })

    # Llenar NaN en nota_std (cuando solo hay 1 evaluaci√≥n)
    stats_df['nota_std'] = stats_df['nota_std'].fillna(0)

    # Nivel de Riesgo
    stats_df['nivel_riesgo'] = stats_df['nota_media'].apply(
        lambda x: obtener_nivel_riesgo_nota(x, umbrales)
    )

    stats_df['aprobado'] = stats_df['nota_media'] >= umbrales['nota_aprobado']

    # Tendencia
    if 'Fecha' in df_calificaciones.columns and df_calificaciones['Fecha'].dtype == 'datetime64[ns]':
        df_sorted = df_calificaciones.sort_values('Fecha')
        stats_df['tendencia'] = df_sorted.groupby('IDEstudiante')['Nota'].apply(
            calcular_tendencia_vectorizada
        )
    else:
        stats_df['tendencia'] = 'ESTABLE'

    return stats_df


# ============================================================================
# AN√ÅLISIS COMPLETO OPTIMIZADO
# ============================================================================

def realizar_analisis_completo(df_asistencia: pd.DataFrame,
                               df_calificaciones: pd.DataFrame,
                               umbrales: Dict = None) -> Dict:
    """
    Orquestador optimizado del an√°lisis completo.

    Args:
        df_asistencia: DataFrame de asistencia
        df_calificaciones: DataFrame de calificaciones
        umbrales: Diccionario de umbrales

    Returns:
        Diccionario con resultados completos del an√°lisis
    """
    if umbrales is None:
        umbrales = UMBRALES

    logger.info("\n" + "=" * 70)
    logger.info("üöÄ INICIANDO AN√ÅLISIS VECTORIZADO (OPTIMIZADO)")
    logger.info("=" * 70)

    # 1. An√°lisis Vectorizados
    logger.info("\nüìä Analizando asistencia...")
    df_asist_res = analizar_asistencia_vectorizado(df_asistencia, umbrales)
    logger.info(f"‚úì Asistencia analizada: {len(df_asist_res)} estudiantes")

    logger.info("\nüìù Analizando rendimiento...")
    df_rend_res = analizar_rendimiento_vectorizado(df_calificaciones, umbrales)
    logger.info(f"‚úì Rendimiento analizado: {len(df_rend_res)} estudiantes")

    # 2. Unir resultados (Full Outer Join para no perder alumnos)
    logger.info("\nüîó Combinando resultados...")
    df_combined = df_asist_res.join(
        df_rend_res,
        how='outer',
        lsuffix='_asist',
        rsuffix='_rend'
    )

    # Llenar NaNs cr√≠ticos
    defaults = {
        'nivel_riesgo_asist': 'SIN_DATOS',
        'nivel_riesgo_rend': 'SIN_DATOS',
        'porcentaje_asistencia': 0.0,
        'nota_media': 0.0,
        'tendencia_asist': 'ESTABLE',
        'tendencia_rend': 'ESTABLE',
        'sesiones_totales': 0,
        'asistencias': 0,
        'faltas': 0,
        'faltas_justificadas': 0,
        'faltas_injustificadas': 0,
        'retrasos': 0,
        'n_evaluaciones': 0,
        'nota_std': 0.0,
        'nota_min': 0.0,
        'nota_max': 0.0,
        'aprobado': False
    }
    df_combined = df_combined.fillna(defaults)

    # 3. Riesgo Combinado (Vectorizado)
    def calc_riesgo_final(row):
        return obtener_nivel_riesgo_combinado(
            row['nivel_riesgo_asist'],
            row['nivel_riesgo_rend']
        )

    df_combined['nivel_riesgo_final'] = df_combined.apply(calc_riesgo_final, axis=1)

    # Reset index para tener IDEstudiante como columna
    df_final = df_combined.reset_index()

    # Renombrar columnas para coincidir con report_generator
    rename_map = {
        'nivel_riesgo_asist': 'nivel_riesgo_asistencia',
        'nivel_riesgo_rend': 'nivel_riesgo_rendimiento',
        'porcentaje_asistencia': 'asist_porcentaje_asistencia',
        'nota_media': 'rend_nota_media',
        'n_evaluaciones': 'rend_n_evaluaciones',
        'tendencia_asist': 'asist_tendencia',
        'tendencia_rend': 'rend_tendencia',
        'faltas': 'asist_faltas',
        'retrasos': 'asist_retrasos',
        'sesiones_totales': 'asist_sesiones_totales',
        'asistencias': 'asist_asistencias',
        'faltas_justificadas': 'asist_faltas_justificadas',
        'faltas_injustificadas': 'asist_faltas_injustificadas',
        'nota_std': 'rend_nota_std',
        'nota_min': 'rend_nota_min',
        'nota_max': 'rend_nota_max',
        'aprobado': 'rend_aprobado'
    }
    df_final = df_final.rename(columns=rename_map)

    # 4. An√°lisis por Cursos (Vectorizado)
    logger.info("\nüè´ Analizando cursos...")

    # Obtener mapa de estudiante -> curso (CORRECCI√ìN: evitar duplicados por estudiante)
    if 'CursoID' in df_asistencia.columns:
        # keep='last' asume que el √∫ltimo registro es el curso actual del estudiante
        mapa_cursos = df_asistencia[['IDEstudiante', 'CursoID']].drop_duplicates(subset=['IDEstudiante'], keep='last')
        mapa_cursos = mapa_cursos.set_index('IDEstudiante')
        df_final_con_curso = df_final.join(mapa_cursos, on='IDEstudiante')
    else:
        df_final_con_curso = df_final.copy()
        df_final_con_curso['CursoID'] = 'CURSO01'

    # Si hay nulos en curso, intentar llenar con calificaciones
    if df_final_con_curso['CursoID'].isnull().any() and 'CursoID' in df_calificaciones.columns:
        mapa_cursos_notas = df_calificaciones[['IDEstudiante', 'CursoID']].drop_duplicates(subset=['IDEstudiante'], keep='last')
        mapa_cursos_notas = mapa_cursos_notas.set_index('IDEstudiante')
        df_final_con_curso['CursoID'] = df_final_con_curso['CursoID'].fillna(
            df_final_con_curso.join(mapa_cursos_notas, on='IDEstudiante', rsuffix='_n')['CursoID_n']
        )

    # Llenar CursoID nulos restantes con valor gen√©rico
    df_final_con_curso['CursoID'] = df_final_con_curso['CursoID'].fillna('CURSO01')

    # Agregar por curso
    analisis_cursos = df_final_con_curso.groupby('CursoID').agg(
        estudiantes=('IDEstudiante', 'count'),
        porcentaje_medio=('asist_porcentaje_asistencia', 'mean'),
        porcentaje_min=('asist_porcentaje_asistencia', 'min'),
        porcentaje_max=('asist_porcentaje_asistencia', 'max'),
        rend_nota_media=('rend_nota_media', 'mean'),
        rend_tasa_aprobados=(
            'rend_aprobado',
            lambda x: (x.sum() / len(x) * 100) if len(x) > 0 else 0
        ),
        estudiantes_riesgo_alto=(
            'nivel_riesgo_final',
            lambda x: (x == 'ALTO').sum()
        ),
        rend_estudiantes_riesgo_alto=(
            'nivel_riesgo_rendimiento',
            lambda x: (x == 'ALTO').sum()
        )
    ).reset_index()

    # Redondear valores
    analisis_cursos['porcentaje_medio'] = analisis_cursos['porcentaje_medio'].round(2)
    analisis_cursos['porcentaje_min'] = analisis_cursos['porcentaje_min'].round(2)
    analisis_cursos['porcentaje_max'] = analisis_cursos['porcentaje_max'].round(2)
    analisis_cursos['rend_nota_media'] = analisis_cursos['rend_nota_media'].round(2)
    analisis_cursos['rend_tasa_aprobados'] = analisis_cursos['rend_tasa_aprobados'].round(2)

    # Renombrar columna para compatibilidad con report_generator
    analisis_cursos = analisis_cursos.rename(columns={'CursoID': 'curso_id'})

    logger.info(f"‚úì {len(analisis_cursos)} cursos analizados")

    # 5. ML (Si aplica)
    logger.info("\nü§ñ Ejecutando Machine Learning...")
    ml_results = None
    if len(df_final) >= umbrales['ml_min_samples']:
        ml_results = ejecutar_ml_optimizado(df_final, umbrales)
        if ml_results and ml_results.get('exito'):
            # Merge ML predictions back
            predicciones = ml_results['predicciones'][['IDEstudiante', 'Cluster', 'NivelRiesgoML']]
            df_final_con_curso = df_final_con_curso.merge(
                predicciones,
                on='IDEstudiante',
                how='left'
            )
            logger.info(f"‚úì ML completado: {len(predicciones)} predicciones")
    else:
        logger.warning(
            f"‚ö†Ô∏è  Insuficientes estudiantes para ML "
            f"({len(df_final)} < {umbrales['ml_min_samples']})"
        )

    # 6. Preparar estructura de salida (compatible con report_generator)
    total = len(df_final_con_curso)
    resumen = {
        'total_estudiantes': total,
        'total_cursos': df_final_con_curso['CursoID'].nunique(),
        'estudiantes_riesgo_alto': (df_final_con_curso['nivel_riesgo_final'] == 'ALTO').sum(),
        'estudiantes_riesgo_medio': (df_final_con_curso['nivel_riesgo_final'] == 'MEDIO').sum(),
        'estudiantes_alerta': (df_final_con_curso['nivel_riesgo_final'] == 'ALERTA').sum(),
        'estudiantes_optimo': (df_final_con_curso['nivel_riesgo_final'] == 'OPTIMO').sum(),
    }

    # Porcentajes
    if total > 0:
        resumen['porcentaje_riesgo_alto'] = resumen['estudiantes_riesgo_alto'] / total * 100
        resumen['porcentaje_riesgo_medio'] = resumen['estudiantes_riesgo_medio'] / total * 100

    # Log final
    logger.info("\n" + "=" * 70)
    logger.info("‚úÖ AN√ÅLISIS COMPLETADO")
    logger.info("=" * 70)
    logger.info(f"Total estudiantes: {resumen['total_estudiantes']}")
    logger.info(f"  - Riesgo ALTO: {resumen['estudiantes_riesgo_alto']}")
    logger.info(f"  - Riesgo MEDIO: {resumen['estudiantes_riesgo_medio']}")
    logger.info(f"  - ALERTA: {resumen['estudiantes_alerta']}")
    logger.info(f"  - √ìPTIMO: {resumen['estudiantes_optimo']}")
    logger.info("=" * 70 + "\n")

    return {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'umbrales': umbrales,
        'analisis_individual': df_final_con_curso,  # DataFrame enriquecido
        'analisis_cursos': analisis_cursos,
        'resumen': resumen,
        'ml': ml_results,
    }


# ============================================================================
# MACHINE LEARNING ROBUSTO CON IMPUTACI√ìN
# ============================================================================

def ejecutar_ml_optimizado(df_features_base: pd.DataFrame,
                          umbrales: Dict) -> Optional[Dict]:
    """
    ML Robustecido con Imputaci√≥n de valores faltantes.

    Args:
        df_features_base: DataFrame con m√©tricas por estudiante
        umbrales: Diccionario de umbrales

    Returns:
        Diccionario con resultados ML o None si falla
    """
    try:
        # Features num√©ricos relevantes
        cols_ml = [
            'asist_porcentaje_asistencia',
            'rend_nota_media',
            'asist_faltas',
            'asist_retrasos',
            'rend_n_evaluaciones'
        ]

        # Filtrar columnas que existen
        cols_existentes = [c for c in cols_ml if c in df_features_base.columns]

        if len(cols_existentes) < 2:
            logger.warning("‚ö†Ô∏è  Insuficientes features para ML")
            return {'exito': False, 'mensaje': 'Insuficientes features'}

        X = df_features_base[cols_existentes].values

        # 1. Imputaci√≥n (Manejo de NaNs)
        imputer = SimpleImputer(strategy='mean')
        X_imp = imputer.fit_transform(X)

        # 2. Escalado
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_imp)

        # 3. Clustering
        n_clusters = min(umbrales['ml_n_clusters'], len(df_features_base) - 1)
        if n_clusters < 2:
            logger.warning("‚ö†Ô∏è  Muy pocos estudiantes para clustering")
            return {'exito': False, 'mensaje': 'Muy pocos estudiantes'}

        kmeans = KMeans(
            n_clusters=n_clusters,
            random_state=umbrales['ml_random_state'],
            n_init=10
        )
        labels = kmeans.fit_predict(X_scaled)

        # Crear DF resultados
        df_pred = df_features_base[['IDEstudiante']].copy()
        df_pred['Cluster'] = labels

        # L√≥gica para asignar nombre de riesgo al cluster basada en centroides
        # Score: menor asistencia + menor nota = mayor riesgo
        score_col_indices = []
        if 'asist_porcentaje_asistencia' in cols_existentes:
            score_col_indices.append(cols_existentes.index('asist_porcentaje_asistencia'))
        if 'rend_nota_media' in cols_existentes:
            score_col_indices.append(cols_existentes.index('rend_nota_media'))

        if score_col_indices:
            # Calcular score por fila (normalizado)
            if len(score_col_indices) == 2:
                df_pred['Temp_Score'] = (
                    X_imp[:, score_col_indices[0]] +
                    (X_imp[:, score_col_indices[1]] * 10)
                )
            else:
                df_pred['Temp_Score'] = X_imp[:, score_col_indices[0]]

            # Score promedio por cluster
            cluster_scores = df_pred.groupby('Cluster')['Temp_Score'].mean().sort_values()

            # Mapeo din√°mico: Cluster con menor score = Mayor Riesgo
            risk_levels = ['ALTO', 'MEDIO', 'ALERTA', 'OPTIMO']
            mapa_riesgo = {}
            for i, (cluster_id, _) in enumerate(cluster_scores.items()):
                if i < len(risk_levels):
                    mapa_riesgo[cluster_id] = risk_levels[i]
                else:
                    mapa_riesgo[cluster_id] = 'OPTIMO'

            df_pred['NivelRiesgoML'] = df_pred['Cluster'].map(mapa_riesgo)
            df_pred = df_pred.drop(columns=['Temp_Score'])
        else:
            # Si no hay features de score, asignar nivel gen√©rico
            df_pred['NivelRiesgoML'] = 'ALERTA'

        # Calcular silhouette score
        silhouette = silhouette_score(X_scaled, labels) if n_clusters < len(df_features_base) else 0

        logger.info(f"  ‚úì Clustering completado: {n_clusters} clusters")
        logger.info(f"  ‚úì Silhouette Score: {silhouette:.3f}")

        return {
            'exito': True,
            'modelo': kmeans,
            'scaler': scaler,
            'imputer': imputer,
            'predicciones': df_pred,
            'n_clusters': n_clusters,
            'silhouette': silhouette,
            'features_usados': cols_existentes
        }

    except Exception as e:
        logger.error(f"‚ùå Error en ML: {str(e)}")
        return {'exito': False, 'mensaje': str(e)}


# ============================================================================
# FUNCIONES DE COMPATIBILIDAD (para GUI antigua)
# ============================================================================

def analizar_asistencia(df_asistencia: pd.DataFrame,
                       umbrales: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Wrapper de compatibilidad para GUI antigua.

    Args:
        df_asistencia: DataFrame de asistencia
        umbrales: Diccionario de umbrales

    Returns:
        Diccionario con resultados (formato antiguo para compatibilidad)
    """
    if umbrales is None:
        umbrales = UMBRALES

    df_resultado = analizar_asistencia_vectorizado(df_asistencia, umbrales)

    # Convertir a dict por estudiante para compatibilidad
    estudiantes = {}
    for est_id, row in df_resultado.iterrows():
        estudiantes[est_id] = row.to_dict()

    # Resumen
    porcentajes = df_resultado['porcentaje_asistencia'].tolist()
    niveles_riesgo = df_resultado['nivel_riesgo'].tolist()

    resumen = {
        'total_estudiantes': len(df_resultado),
        'porcentaje_asistencia_promedio': np.mean(porcentajes) if porcentajes else 0.0,
        'estudiantes_riesgo_alto': sum(1 for n in niveles_riesgo if n == 'ALTO'),
        'estudiantes_riesgo_medio': sum(1 for n in niveles_riesgo if n == 'MEDIO'),
        'estudiantes_alerta': sum(1 for n in niveles_riesgo if n == 'ALERTA'),
        'estudiantes_sin_riesgo': sum(1 for n in niveles_riesgo if n == 'NINGUNO'),
    }

    return {
        'estudiantes': estudiantes,
        'resumen': resumen
    }


def analizar_rendimiento(df_calificaciones: pd.DataFrame,
                        umbrales: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Wrapper de compatibilidad para GUI antigua.

    Args:
        df_calificaciones: DataFrame de calificaciones
        umbrales: Diccionario de umbrales

    Returns:
        Diccionario con resultados (formato antiguo para compatibilidad)
    """
    if umbrales is None:
        umbrales = UMBRALES

    df_resultado = analizar_rendimiento_vectorizado(df_calificaciones, umbrales)

    # Convertir a dict por estudiante para compatibilidad
    estudiantes = {}
    for est_id, row in df_resultado.iterrows():
        estudiantes[est_id] = row.to_dict()

    # Resumen
    notas_medias = df_resultado['nota_media'].tolist()
    niveles_riesgo = df_resultado['nivel_riesgo'].tolist()
    aprobados = df_resultado['aprobado'].tolist()

    resumen = {
        'total_estudiantes': len(df_resultado),
        'nota_media_general': np.mean(notas_medias) if notas_medias else 0.0,
        'tasa_aprobados': sum(aprobados) / len(aprobados) * 100 if aprobados else 0.0,
        'estudiantes_riesgo_alto': sum(1 for n in niveles_riesgo if n == 'ALTO'),
        'estudiantes_riesgo_medio': sum(1 for n in niveles_riesgo if n == 'MEDIO'),
        'estudiantes_alerta': sum(1 for n in niveles_riesgo if n == 'ALERTA'),
        'estudiantes_sin_riesgo': sum(1 for n in niveles_riesgo if n == 'NINGUNO'),
    }

    return {
        'estudiantes': estudiantes,
        'resumen': resumen
    }


def clasificar_estudiantes(resultados_asist: Dict[str, Any],
                          resultados_rend: Dict[str, Any],
                          umbrales: Dict[str, Any] = None) -> pd.DataFrame:
    """
    Clasifica estudiantes por nivel de riesgo (wrapper de compatibilidad).

    Args:
        resultados_asist: Resultados del an√°lisis de asistencia
        resultados_rend: Resultados del an√°lisis de rendimiento
        umbrales: Diccionario de umbrales

    Returns:
        DataFrame con clasificaci√≥n de estudiantes
    """
    if umbrales is None:
        umbrales = UMBRALES

    # Obtener todos los estudiantes √∫nicos
    estudiantes_asist = set(resultados_asist.get('estudiantes', {}).keys())
    estudiantes_rend = set(resultados_rend.get('estudiantes', {}).keys())
    todos_estudiantes = estudiantes_asist | estudiantes_rend

    clasificacion = []

    for est_id in todos_estudiantes:
        # Obtener an√°lisis de asistencia
        asist = resultados_asist.get('estudiantes', {}).get(est_id, {})

        # Obtener an√°lisis de rendimiento
        rend = resultados_rend.get('estudiantes', {}).get(est_id, {})

        # Calcular nivel de riesgo combinado
        nivel_riesgo_final = obtener_nivel_riesgo_combinado(
            asist.get('nivel_riesgo', 'SIN_DATOS'),
            rend.get('nivel_riesgo', 'SIN_DATOS')
        )

        clasificacion.append({
            'IDEstudiante': est_id,
            'nivel_riesgo_asistencia': asist.get('nivel_riesgo', 'SIN_DATOS'),
            'nivel_riesgo_rendimiento': rend.get('nivel_riesgo', 'SIN_DATOS'),
            'nivel_riesgo_final': nivel_riesgo_final,
            'porcentaje_asistencia': asist.get('porcentaje_asistencia', 0.0),
            'nota_media': rend.get('nota_media', 0.0),
            'asist_tendencia': asist.get('tendencia', 'ESTABLE'),
            'rend_tendencia': rend.get('tendencia', 'ESTABLE'),
        })

    # Convertir a DataFrame y ordenar por nivel de riesgo
    df_clasificacion = pd.DataFrame(clasificacion)

    # Ordenar por nivel de riesgo (ALTO -> MEDIO -> ALERTA -> OPTIMO)
    orden_riesgo = {'ALTO': 0, 'MEDIO': 1, 'ALERTA': 2, 'OPTIMO': 3, 'SIN_DATOS': 4}
    df_clasificacion['_orden'] = df_clasificacion['nivel_riesgo_final'].map(orden_riesgo)
    df_clasificacion = df_clasificacion.sort_values('_orden').drop('_orden', axis=1)

    return df_clasificacion


def analizar_con_ml(df_asistencia: pd.DataFrame,
                    df_calificaciones: pd.DataFrame,
                    umbrales: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Ejecuta el an√°lisis completo con Machine Learning (wrapper de compatibilidad).

    Args:
        df_asistencia: DataFrame de asistencia
        df_calificaciones: DataFrame de calificaciones
        umbrales: Diccionario de umbrales

    Returns:
        Diccionario con resultados del an√°lisis ML
    """
    # Usar la funci√≥n optimizada completa
    resultados = realizar_analisis_completo(df_asistencia, df_calificaciones, umbrales)
    return resultados.get('ml', {'exito': False})


# ============================================================================
# FUNCI√ìN DE TEST
# ============================================================================

def test_analysis():
    """Test b√°sico del m√≥dulo de an√°lisis."""
    logger.info("üß™ Ejecutando tests de analysis...")

    # Crear datos de prueba
    df_asist = pd.DataFrame({
        'IDEstudiante': ['EST001', 'EST001', 'EST002', 'EST002'] * 5,
        'CursoID': ['3ESO-A'] * 20,
        'Fecha': pd.date_range('2024-01-01', periods=20),
        'Presente': [True, True, False, True] * 5,
        'Retraso': [False] * 20,
        'FaltaJustificada': [False] * 20,
    })

    df_calif = pd.DataFrame({
        'IDEstudiante': ['EST001', 'EST001', 'EST002', 'EST002'],
        'CursoID': ['3ESO-A'] * 4,
        'Evaluacion': ['Eval1', 'Eval2', 'Eval1', 'Eval2'],
        'Nota': [7.5, 8.0, 5.0, 4.5],
        'Competencia': ['CE1', 'CE2', 'CE1', 'CE2'],
        'Peso': [1.0] * 4,
    })

    try:
        # Test an√°lisis completo
        resultados = realizar_analisis_completo(df_asist, df_calif)

        assert 'analisis_cursos' in resultados
        assert 'analisis_individual' in resultados
        assert len(resultados['analisis_individual']) == 2

        logger.info("‚úÖ Tests de analysis PASADOS")
        return True

    except Exception as e:
        logger.error(f"‚ùå Test fall√≥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    test_analysis()
